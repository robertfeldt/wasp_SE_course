\subsection{Towards a roadmap on software engineering for responsible AI \cite{pp2}}
This paper focuses on creating practical ways to responsible and ethical AI systems that can be trusted. 
It points out the fact that we have many high-level ethical principles, yet there is a gap in using those ideas in actual products. 
This kind of work is important because it helps us bring AI into the real world responsibly. 
Also, it is related to my research, because XAI can be one way of making sure that AI systems are actually doing what we think they are doing.
Hence, they suggest three ways to fix the issue:
\begin{itemize}
    \item Having rules or guidelines at different levels. Including industry, organization, and teams. This way, we make sure everyone developing AI is on the same page.
    \item Having ethics embedded in the development process. This means that fairness, privacy, and safety are checked at every step.
    \item Designing AI systems while having responsibility in mind. 
    This translates to techniques like accountability tools or privacy-friendly methods like federated learning.
\end{itemize}
    
This kind of work is important because it helps us bring AI into the real world responsibly. 
Finally, this paper is related to my research, because XAI can be one way of making sure that AI systems are actually doing what we think they are doing.

So one way of producing responsible AI systems is designing tests that uncover the inner workings of an AI system but designing tests requires a mental model of how things work, which I believe requires XAI.